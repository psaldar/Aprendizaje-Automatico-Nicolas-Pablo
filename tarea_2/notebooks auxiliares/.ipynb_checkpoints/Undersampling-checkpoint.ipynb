{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis de undersampling Tarea 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estudiantes:\n",
    "- Nicolás Prieto Escobar\n",
    "- Pablo A. Saldarriaga Aristizabal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema:\n",
    "\n",
    "Se cuenta con información georeferenciada de accidentes que han ocurrido en diferentes barrios en la ciudad de Medellín durante el año 2017, se tienen alrededor de 312 barrios diferentes en el conjunto de datos. El objetivo para este caso de estudio, es hora a hora tratar de predecir si en un barrio determinado ocurrirá o no un accidente en base a las condiciones climáticas actuales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de paquetes para ejecutar este Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import PredefinedHoldoutSplit\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Silencio warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fijamos la semilla aleatoria para garantizar replicabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1  # use this constant seed everywhere\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)  # `python` built-in pseudo-random generator\n",
    "np.random.seed(SEED)  # numpy pseudo-random generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datos para la tarea\n",
    "Para utilizar técnicas de ingeniería de características, en esta tarea consideramos la información del barrio \"La Candelaria\" en el periodo de tiempo Junio 1 a Diciembre 31 de 2017. Las variables climáticas disponibles en el conjunto de datos son:\n",
    "\n",
    "- icon\n",
    "- precipIntensity\n",
    "- precipProbability\n",
    "- temperature\n",
    "- apparentTemperature\n",
    "- dewPoint\n",
    "- humidity\n",
    "- windSpeed\n",
    "- cloudCover\n",
    "- uvIndex\n",
    "- visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lectura del dataset a usar (se usa un subconjunto del dataset por motivos de tiempo)\n",
    "data = pd.read_csv('data/data_tarea1.csv',sep =',')\n",
    "data['TW'] = pd.to_datetime(data['TW'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregamos variables relacionadas a la fecha, como lo son la hora en la que occure el accidente y el día de la semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Agregar otras features\n",
    "data['hora'] = data['TW'].dt.hour\n",
    "data['dia_sem'] = data['TW'].dt.dayofweek\n",
    "\n",
    "data= pd.get_dummies(data, columns=['hora'])\n",
    "data= pd.get_dummies(data, columns=['icon'])\n",
    "data= pd.get_dummies(data, columns=['dia_sem'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicional a las variables que se crearon, realizaremos un aumento del conjunto de datos en base a uno de los estadisticos que da información distribucional de las variables, la cual es la media. Las variables climaticas que estamos considerando, son series de tiempo para las cuales, se les verificó previamente su estacionariedad, así que a forma de obtener una mayor información de cada una de la series, agregamos para cada una, una media móvil de las últimas 5 horas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = '5H'\n",
    "variables = ['temperature','precipIntensity','apparentTemperature','dewPoint','humidity','windSpeed','cloudCover','visibility']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aux = data.copy()\n",
    "data_aux.index = data_aux.TW\n",
    "data_aux = data_aux.sort_index()\n",
    "data_aux = data_aux.drop(columns = 'TW')\n",
    "resample_data = data_aux[variables].rolling(freq, closed = 'left').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pivot = data_aux.pivot_table(values=variables, index='TW',columns='BARRIO', aggfunc=sum)\n",
    "data_mean = data_pivot.rolling(freq, closed = 'left').mean().stack().reset_index(drop = False)\n",
    "\n",
    "col_means = [*data_mean.columns[:2]]\n",
    "for col in data_mean.columns[2:]:\n",
    "    col_means.append(col + '_mean')\n",
    "    \n",
    "data_mean.columns = col_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(data_mean, how = 'left', on = ['TW','BARRIO'])\n",
    "data = data.dropna().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Seleccionar variable entrada y salida \n",
    "X = data.drop(\"Accidente\", 1).reset_index(drop=True)       # feature matrix \n",
    "y = data['Accidente'].reset_index(drop=True)               # target feature\n",
    "X = X[X.columns[2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['precipIntensity', 'precipProbability', 'temperature',\n",
       "       'apparentTemperature', 'dewPoint', 'humidity', 'windSpeed',\n",
       "       'cloudCover', 'uvIndex', 'visibility', 'hora_0', 'hora_1', 'hora_2',\n",
       "       'hora_3', 'hora_4', 'hora_5', 'hora_6', 'hora_7', 'hora_8', 'hora_9',\n",
       "       'hora_10', 'hora_11', 'hora_12', 'hora_13', 'hora_14', 'hora_15',\n",
       "       'hora_16', 'hora_17', 'hora_18', 'hora_19', 'hora_20', 'hora_21',\n",
       "       'hora_22', 'hora_23', 'icon_clear-day', 'icon_clear-night',\n",
       "       'icon_cloudy', 'icon_fog', 'icon_partly-cloudy-day',\n",
       "       'icon_partly-cloudy-night', 'icon_rain', 'dia_sem_0', 'dia_sem_1',\n",
       "       'dia_sem_2', 'dia_sem_3', 'dia_sem_4', 'dia_sem_5', 'dia_sem_6',\n",
       "       'apparentTemperature_mean', 'cloudCover_mean', 'dewPoint_mean',\n",
       "       'humidity_mean', 'precipIntensity_mean', 'temperature_mean',\n",
       "       'visibility_mean', 'windSpeed_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5112, 56)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza la partición del conjunto de datos en 3 conjuntos:\n",
    "- Train (60%)\n",
    "- Validation (20%)\n",
    "- Test (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Partir en train y test los datos\n",
    "X_train, X_val1, y_train, y_val1 = train_test_split(X, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.40,  random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_val1, y_val1,\n",
    "                                                    stratify=y_val1, \n",
    "                                                    test_size=0.5,  random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3067, 56)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1023, 56)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022, 56)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que los datos se encuentran muy desbalanceados, realizamos un undersampling de forma tal que obtengamos una proporcion de 50%-50% entre la cantidad de 1's y 0's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hacer undersampling (los datos estan desbalanceados)\n",
    "tra_0 = int(len(y_train) - y_train.sum())\n",
    "tra_1 = int(y_train.sum())\n",
    "\n",
    "prop_deseada_under = 0.5\n",
    "mul_updown = (tra_0 * prop_deseada_under - tra_1 * (1 - prop_deseada_under)) / (tra_0 * prop_deseada_under)   \n",
    "fac_1 = int(tra_0 * (1 - mul_updown))\n",
    "\n",
    "ratio_u = {0 : fac_1, 1 : tra_1}\n",
    "rus = RandomUnderSampler(sampling_strategy = ratio_u, random_state=42)\n",
    "X_train, y_train = rus.fit_sample(X_train, y_train)\n",
    "\n",
    "X_tr = X_train\n",
    "y_tr = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(634, 56)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tipo de método que usamos para la parte de selección de variables, es un método de envoltura, por lo que definiremos un modelo basado en árboles que nos permita tener una idea de que tan bien se ajusta inicialmente los datos a un modelo de clasificación.\n",
    "\n",
    "Por otro lado, estamos considerando un método de forward selection implementado desde cero, al igual que forward selection y backward selection que tiene el paquete mlxextend. La métrica que utilizaremos para la selección de variables a medida que se hagan la iteración de los modelos, es la relacionada con la Curva ROC-AUC.\n",
    "\n",
    "Otras métricas que utilizamos para evaluar el desempeño del modelo en el conjunto de prueba son:\n",
    "- F1 Score\n",
    "- Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Este es el modelo que sera explotado por los metodos de envoltura\n",
    "clf = ExtraTreesClassifier(n_estimators=70, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De este caso de estudio, podemos ver que el rendimiento que tiene solo un subconjunto de variables es mejor para los 3 metodos en comparación a utilizar la totalidad de variables disponibles, igualmente vemos que el desempeño de los 3 metodos en el conjunto de test es muy parecido entre ellos, además de obtener resultados prometedores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
