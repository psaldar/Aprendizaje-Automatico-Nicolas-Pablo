{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solución Tarea 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estudiantes:\n",
    "- Nicolás Prieto Escobar\n",
    "- Pablo A. Saldarriaga Aristizabal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nota: para que los plots se generen y se vean bien, es necesario ejecutar todo el notebook y tener la carpeta  de github clonada en el PC local. Descargar solo el html NO generará bien los plots, ya que se usan otros html que están en un subdirectorio de donde está este notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema:\n",
    "\n",
    "Se cuenta con información georeferenciada de accidentes que han ocurrido en diferentes barrios en la ciudad de Medellín durante el año 2017. \n",
    "\n",
    "En este ejemplo, se usarán solo los datos de los accidentes que estén en los barrios de la comuna 14, El Poblado. Lo que se pretende es mostrar las ventajas que se tiene al usar una técnica de clusters basados en densidad (DBSCAN) para hallar los clusters de accidentalidad más importante de esa comuna.\n",
    "\n",
    "Se analizará el resultado final obtenido por esta técnica y se hará un análisis de sensbilidad de algunso de sus parámetros (tipo de distancia usada, radio de las vecindades, etc).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza y preparacion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lectura de datos\n",
    "\n",
    "### crear carpeta resultados\n",
    "import os\n",
    "if not os.path.exists('pruebas/'):\n",
    "    os.makedirs('pruebas')\n",
    "\n",
    "### Leer datos\n",
    "import pandas as pd\n",
    "datos = pd.read_csv('data/proc_accidentes_2017.csv')\n",
    "\n",
    "\n",
    "### Dejar solo accidentes del Poblado\n",
    "lista_poblado = \"\"\"\n",
    "ElGuamal\n",
    "BarrioColombia\n",
    "VillaCarlota\n",
    "Castropol\n",
    "Lalinde\n",
    "LasLomasNo1\n",
    "LasLomasNo2\n",
    "AltosdelPoblado\n",
    "ElTesoro\n",
    "LosNaranjos\n",
    "LosBalsosNo1\n",
    "SanLucas\n",
    "ElDiamanteNo2\n",
    "ElCastillo\n",
    "LosBalsosNo2\n",
    "Alejandria\n",
    "LaFlorida\n",
    "ElPoblado\n",
    "Manila\n",
    "Astorga\n",
    "PatioBonito\n",
    "LaAguacatala\n",
    "SantaMariadeLosÁngeles\n",
    "\"\"\"\n",
    "lista_poblado_l = lista_poblado.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dejar solo barrios del poblado\n",
    "datos_pob = datos[datos['BARRIO'].isin(lista_poblado_l)]\n",
    "\n",
    "### Eliminar un dato outlier raro, cuyas coordenadas quedan en san antonio de prado\n",
    "datos_pob = datos_pob[datos_pob['Lon']>-75.62] \n",
    "\n",
    "\n",
    "### Preparacion inicial de datos\n",
    "lat = datos_pob['Lat']\n",
    "lon = datos_pob['Lon']\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Para que quede mejor el plot, le sumo un random pequeno\n",
    "### Esto lo hago porque en la base de datos hay varias observaciones con\n",
    "### exactamente la misma coordenada, esto probablemente sea una imprecision\n",
    "### al etiquetar la ubicaciion del accidente, y en el mapa quedaba un punto\n",
    "### encima del otro y se notaba que ahi habia varios accidentes\n",
    "lats=[]\n",
    "lons=[]\n",
    "for i in range(len(lat)):\n",
    "    lats.append(0.0005*random.random())\n",
    "    lons.append(0.0005*random.random())\n",
    "\n",
    "lat = lat + lats\n",
    "lon = lon + lons\n",
    "\n",
    "datos_pob['Lat'] = lat\n",
    "datos_pob['Lon'] = lon\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Funcion auxiliar para hacer los plots:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Plotting\n",
    "### Ploteo en mapa los clusters\n",
    "import gmplot \n",
    "def plotmap(etiqs, nombre):\n",
    "    \n",
    "    ## Creo el plot\n",
    "    gmap3 = gmplot.GoogleMapPlotter(lat.mean(), lon.mean(), 14) \n",
    "    \n",
    "    colors_list = [ '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080', '#e6beff', '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1', '#000075', '#ffffff','#e6194b', '#000000', '#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080', '#e6beff', '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1', '#000075', '#808080', '#ffffff', '#000000']\n",
    "    \n",
    "    for i in range(max(etiqs)+1):\n",
    "        latitude_list = np.array(lat)[np.where(np.array(etiqs)==i)]\n",
    "        longitude_list = np.array(lon)[np.where(np.array(etiqs)==i)]\n",
    "            \n",
    "        # Pintar puntos de cada cluster, como circulos de cada color\n",
    "        gmap3.scatter( latitude_list, longitude_list, colors_list[i], \n",
    "                                      size = 8, marker = False ) \n",
    "          \n",
    "    \n",
    "        \n",
    "    ### Pinto los que quedaron como outliers, son circulos grises\n",
    "    latitude_list = np.array(lat)[np.where(np.array(etiqs)==-1)]\n",
    "    longitude_list = np.array(lon)[np.where(np.array(etiqs)==-1)]\n",
    "    gmap3.scatter( latitude_list, longitude_list, 'gray', \n",
    "                                  size = 8, marker = False )     \n",
    "        \n",
    "    \n",
    "    ### Guardo el plot\n",
    "    gmap3.draw( \"pruebas/\"+nombre+\".html\" ) \n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering final obtenido con dbscan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, mostraremos el resultado final obtenido al hacer clustering con dbscan, el cual obtuvimos luego de evaluar distintos metodos, hiperparametros y distancias en el modelo.\n",
    "Mostramos aqui este resultado para no tener que mostrar de nuevo este mapa en cada ocasion futura. Sin embargo, todos estos parametros obtenidos fueron el resultado de varias evaluaciones (luego de mostrar el mapa con el resultado final del clustering, mostraremos el analisis de sensibilidad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############ Clustering DBSCAN\n",
    "\n",
    "### Usar dbscan para clustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "kms_per_radian = 6371.0088  ### Para poder usar km se usa esto\n",
    "distancia_en_km = 0.18   ### El radio de cada bola del metodo, en este caso es de 0.18km o 180m\n",
    "\n",
    "epsilon = distancia_en_km / kms_per_radian  ### Esto es auxiliar, para poder usar km con las coordenadas\n",
    "\n",
    "min_points = 20  ### Elegimos que para que un punto sea considerado denso, debe haber al menos 20 puntos en su bola\n",
    "clu = DBSCAN(eps=epsilon, min_samples=min_points, metric='manhattan')  ## Usar dbscan, con metrica L1 o manhattan\n",
    "clu.fit(np.radians(datos_pob[['Lat','Lon']].values))\n",
    "\n",
    "etiqs = list(clu.labels_) ### Clusters encontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"600\"\n",
       "            src=\"pruebas/map_final.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1eedbd09588>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Plotear resultado clusters dbscan\n",
    "plotmap(etiqs, 'map_final')\n",
    "\n",
    "\n",
    "### Mostrar aqui el html\n",
    "from IPython.display import IFrame\n",
    "IFrame(src='pruebas/map_final.html', width=700, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que los resultados obtenidos con dbscan son satisfactorios: se logran encontrar muchas de las agrupaciones de accidentalidad en los sitios donde el sentido común nos dice que se esperaba encontrarlas (glorieta de la aguacatala, puente Gilberto Echeverri Mejía, etc), y además notamos que el uso del clustering por densidad permite armar clusters que pueden tener distintas formas y tamaños (notar que algunas secciones como todo el parque Lleras y la 10 quedan en el mismo cluster, a pesar de ser zonas alargadas, mientras que también hay zonas pequeñas como la glorieta de la agucatala que también terminan formando un cluster).\n",
    "\n",
    "Ademas, notar que tambien el método logra detectar que ocurren muchos accidentes en la ciudad que ocurren por simple casualidad pero no representan puntos de gran interés: estos son los puntos grises en el plot. Representarían los outliers de este modelo, son accidentes que ocurrieron pero no se asociaron exactamente a las zonas con dinámicas más comunes de accidentalidad en la zona. Notar que estos puntos están regados a través de todo el mapa, tal como se esperaba ver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de sensibilidad "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habiendo mostrado ya el resultado final obtenido, mostraremos entonces en esta seccion el analisis de sensibilidad relacionado. Lo que haremos ahora es entonces mostrar como diversas partes del modelo (distancia usada, hiperaparametros, etc) afectaban el resultado y asi sustentaremos porque nos quedamos con el resultado final mostrado anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ventajas de la distancia de manhattan sobre otros tipos de distancias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el método final, se usa la distancia de Manhattan en el DBSCAN. Aquí se analizan los resultados obtenidos por otro par de métricas para sustentar la ventaja de la métrica de manhattan sobre las demás en este caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Clustering DBSCAN con distancia euclideana (L2)\n",
    "\n",
    "### Usar dbscan para clustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "kms_per_radian = 6371.0088  ### Para poder usar km se usa esto\n",
    "distancia_en_km = 0.18   ### El radio de cada bola del metodo, en este caso es de 0.18km o 180m\n",
    "\n",
    "epsilon = distancia_en_km / kms_per_radian  ### Esto es auxiliar, para poder usar km con las coordenadas\n",
    "\n",
    "min_points = 20  ### Elegimos que para que un punto sea considerado denso, debe haber al menos 20 puntos en su bola\n",
    "clu_l2 = DBSCAN(eps=epsilon, min_samples=min_points, metric='euclidean')  ## Usar dbscan, con metrica L2 o euclideana\n",
    "clu_l2.fit(np.radians(datos_pob[['Lat','Lon']].values))\n",
    "\n",
    "etiqs_l2 = list(clu_l2.labels_) ### Clusters encontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"600\"\n",
       "            src=\"pruebas/map_euclidean.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1eede559320>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Plotear resultado clusters dbscan\n",
    "plotmap(etiqs_l2, 'map_euclidean')\n",
    "\n",
    "\n",
    "### Mostrar aqui el html\n",
    "from IPython.display import IFrame\n",
    "IFrame(src='pruebas/map_euclidean.html', width=700, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que al usar la distancia euclideana, termina juntando casi todos los puntos en un mismo cluster que atraviesa practicamente toda la zona analizada. \n",
    "\n",
    "Esto ocurre porque estamos manteniendo los distintos parametros iguales, y al usar distancia euclideana van a caber mas puntos en las vecindades que estamos formando (la distancia l1 siempre es mayor o igual a la l2). Esto ocasiona que se conecten muchas mas vecindades entre si, generando entonces un cluster gigante como el que se muestra en la imagen.\n",
    "\n",
    "Cuando nos desplazamos en la ciudad, las calles por lo general son en forma de cuadrícula, y es por esta razón que tiene mucho más sentido medir las distancias usando la distancia de manhattan que la distancia euclideana: los carros no pueden atravesar los edificios, sino que deben seguir las vías y es en las vías donde hay accidentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Clustering DBSCAN con distancia infinita (L inf)\n",
    "\n",
    "### Usar dbscan para clustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "kms_per_radian = 6371.0088  ### Para poder usar km se usa esto\n",
    "distancia_en_km = 0.18   ### El radio de cada bola del metodo, en este caso es de 0.18km o 180m\n",
    "\n",
    "epsilon = distancia_en_km / kms_per_radian  ### Esto es auxiliar, para poder usar km con las coordenadas\n",
    "\n",
    "min_points = 20  ### Elegimos que para que un punto sea considerado denso, debe haber al menos 20 puntos en su bola\n",
    "clu_linf = DBSCAN(eps=epsilon, min_samples=min_points, metric='chebyshev')  ## Usar dbscan, con metrica L1 o infinita\n",
    "clu_linf.fit(np.radians(datos_pob[['Lat','Lon']].values))\n",
    "\n",
    "etiqs_linf = list(clu_linf.labels_) ### Clusters encontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"600\"\n",
       "            src=\"pruebas/map_infinito.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1eed90875f8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Plotear resultado clusters dbscan\n",
    "plotmap(etiqs_linf, 'map_infinito')\n",
    "\n",
    "\n",
    "### Mostrar aqui el html\n",
    "from IPython.display import IFrame\n",
    "IFrame(src='pruebas/map_infinito.html', width=700, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, al usar la distancia infinito, se forma un supercluster aun más grande que el que se formaba con la distancia euclideana.\n",
    "\n",
    "Esto ocurre porque se sabe que l1 >= l2 >= ... >= l infinito.  Por esta razón, en este caso las vecindades probablemente contengan aún mas puntos cada una que con la métrica euclideana, y esto termina haciendo que las vecindades queden mucho más conectadas entre sí y se forme un cluster aún más grande.\n",
    "\n",
    "Al igual que con la euclideana, el movimiento de los carros en la ciudad tampoco tiene sentido que sea basado en la distancia infinito. La manera más correcta de representar ese movimiento es usando al distancia de manhattan y por eso tiene sentido que con la métrica de manhattan se obtengan los mejores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparación para algunos valores del parámetro de puntos mínimos en una bola para ser considerada densa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, comparamos que ocurre cuando ponemos un valor de puntos mínimos de una bola densa muy alto o muy bajo, evidenciando así la importancia de elegir bien dicho valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Clustering DBSCAN con minimo de puntos de bola densa muy bajo\n",
    "\n",
    "### Usar dbscan para clustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "kms_per_radian = 6371.0088  ### Para poder usar km se usa esto\n",
    "distancia_en_km = 0.18   ### El radio de cada bola del metodo, en este caso es de 0.18km o 180m\n",
    "\n",
    "epsilon = distancia_en_km / kms_per_radian  ### Esto es auxiliar, para poder usar km con las coordenadas\n",
    "\n",
    "min_points = 5  ### Elegimos que para que un punto sea considerado denso, debe haber al menos 5 puntos en su bola\n",
    "clu_lowminpts = DBSCAN(eps=epsilon, min_samples=min_points, metric='manhattan')  ## Usar dbscan, con metrica L1 o manhattan\n",
    "clu_lowminpts.fit(np.radians(datos_pob[['Lat','Lon']].values))\n",
    "\n",
    "etiqs_lowminpts = list(clu_lowminpts.labels_) ### Clusters encontrados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"600\"\n",
       "            src=\"pruebas/map_lowminpts.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1eedbcdc4e0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Plotear resultado clusters dbscan\n",
    "plotmap(etiqs_lowminpts, 'map_lowminpts')\n",
    "\n",
    "\n",
    "### Mostrar aqui el html\n",
    "from IPython.display import IFrame\n",
    "IFrame(src='pruebas/map_lowminpts.html', width=700, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, al poner que para que una bola sea densa se necesita un numero mas bajo de puntos que el que teniamos (5 en vez de 20), vemos que se forma un supercluster verde y ademas se forman muchos clusters muy pequeños en partes del mapa. \n",
    "\n",
    "El supercluster ocurre porque como ya se requieren menos puntos para ser densa, se crean entonces muchas más bolas densas que en el caso original, esto conlleva a que haya mucha mayor posibilidad de que se conecten esos puntos entre sí y terminen formando una gran vecindad, tal como ocurrió.\n",
    "Además, al requerir menos puntos para que una bola sea densa, se forman clusters en sitios que antes eran considerados como outliers por no alcanzar a llegar al umbral. Esto forma clusters en sitios que quizás no sean tan importantes o relevantes como los demás.\n",
    "\n",
    "Estas razones apoyan el hecho de que elegir un valor muy pequeño de número mínimo de puntos para que la bola sea densa no es la mejor opción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Clustering DBSCAN con minimo de puntos de bola densa muy alto\n",
    "\n",
    "### Usar dbscan para clustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "kms_per_radian = 6371.0088  ### Para poder usar km se usa esto\n",
    "distancia_en_km = 0.18   ### El radio de cada bola del metodo, en este caso es de 0.18km o 180m\n",
    "\n",
    "epsilon = distancia_en_km / kms_per_radian  ### Esto es auxiliar, para poder usar km con las coordenadas\n",
    "\n",
    "min_points = 50  ### Elegimos que para que un punto sea considerado denso, debe haber al menos 50 puntos en su bola\n",
    "clu_highminpts = DBSCAN(eps=epsilon, min_samples=min_points, metric='manhattan')  ## Usar dbscan, con metrica L1 o manhattan\n",
    "clu_highminpts.fit(np.radians(datos_pob[['Lat','Lon']].values))\n",
    "\n",
    "etiqs_highminpts = list(clu_highminpts.labels_) ### Clusters encontrados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"600\"\n",
       "            src=\"pruebas/map_highminpts.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1eedbcdc8d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Plotear resultado clusters dbscan\n",
    "plotmap(etiqs_highminpts, 'map_highminpts')\n",
    "\n",
    "\n",
    "### Mostrar aqui el html\n",
    "from IPython.display import IFrame\n",
    "IFrame(src='pruebas/map_highminpts.html', width=700, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este segundo caso, lo que se hizo fue aumentar el numero mínimo de puntos de de una bola para ser considerada densa de 20 a 50. Como podemos ver, el principal efecto que tuvo hacer esto fue que se crearon muchas menos zonas densas, esto desencadenó que algunas partes del mapa donde habíamos encontrado la existencia de clusters ya sean marcadas como outliers en vez de clusters debido a que, a pesar de que hubo varios accidentes ahí, su número no fue suficiente para ser considerada densa. \n",
    "\n",
    "Este resultado no lo consideramos tan bueno como el original, debido a que se quitaron clusters de algunas zonas que se conoce que tienen alta accidentalidad en la ciudad (por ejemplo, las zonas cercanas al mall El Tesoro, las cuales son muy frecuentadas por visitantes y por ende tienen presencia de varios choques, ya son consideradas como outliers en este caso). Lo que ocurrió entonces es que al aumentar tanto el número mínimo de puntos de una bola densa, a pesar de que se conservaron los clusters de mayor tamaño, se perdieron algunos otros clusters que no eran tan grandes pero que también eran de interés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparación para algunos valores del parámetro de radio de las bolas (vecindades)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El último análisis de sensibilidad que haremos consiste en ver que ocurre cuando variamos el radio de las vecindades del método. Veremos que pasa al poner un radio muy alto o muy bajo en este ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Clustering DBSCAN con radio de bola muy bajo\n",
    "\n",
    "### Usar dbscan para clustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "kms_per_radian = 6371.0088  ### Para poder usar km se usa esto\n",
    "distancia_en_km = 0.03   ### El radio de cada bola del metodo, en este caso es de 0.03km o 30m\n",
    "\n",
    "epsilon = distancia_en_km / kms_per_radian  ### Esto es auxiliar, para poder usar km con las coordenadas\n",
    "\n",
    "min_points = 20  ### Elegimos que para que un punto sea considerado denso, debe haber al menos 20 puntos en su bola\n",
    "clu_lowrad = DBSCAN(eps=epsilon, min_samples=min_points, metric='manhattan')  ## Usar dbscan, con metrica L1 o manhattan\n",
    "clu_lowrad.fit(np.radians(datos_pob[['Lat','Lon']].values))\n",
    "\n",
    "etiqs_lowrad = list(clu_lowrad.labels_) ### Clusters encontrados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"600\"\n",
       "            src=\"pruebas/map_lowrad.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1eedaea5940>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Plotear resultado clusters dbscan\n",
    "plotmap(etiqs_lowrad, 'map_lowrad')\n",
    "\n",
    "\n",
    "### Mostrar aqui el html\n",
    "from IPython.display import IFrame\n",
    "IFrame(src='pruebas/map_lowrad.html', width=700, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, evaluamos un parámetro muy bajo para el valor del radio de cada bola. Al ponerle un valor de solo 30 metros al radio de cada bola, las bolas cubren una región muy pequeña y no son capaces de cubrir nisiquiera la zona entre una calle y la otra. Como se ve en la imagen, prácticamente los únicos cluster que se muestran son los que ocurren exactamente en la misma intersección, pero el método no es capaz de agrupar en una misma bola los accidentes que ocurren en dos intersecciones consecutivas de una misma calle. Esto se muestra evidente al examinar la zona del parque Lleras: en cada intersección de la calle 10 hay varios accidentes; sin embargo, al tener un radio de bola tan bajo, los accidentes en intersecciones consecutivas no alcanzan a conectarse, conllevando así a que no pueda formarse bien el cluster de todo el parque lleras y la calle 10. \n",
    "\n",
    "Este caso entonces muestra que el parámetro de radio de la bola no es muy adecuado: usar 30m es un valor muy bajo ya que tiene mucho más sentido considerar que las intersecciones consecutivas en una misma calle tienen relación en cuanto a la accidentalidad (la distancia entre una calle y otra suele ser casi siempre mayor a 30m). Debido a esto, el método no puede conectar varias bolas entre sí para formar clusters más grandes de accidentalidad para representar bien las zonas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Clustering DBSCAN con radio de bola muy alto\n",
    "\n",
    "### Usar dbscan para clustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "kms_per_radian = 6371.0088  ### Para poder usar km se usa esto\n",
    "distancia_en_km = 0.3   ### El radio de cada bola del metodo, en este caso es de 0.3km o 300m\n",
    "\n",
    "epsilon = distancia_en_km / kms_per_radian  ### Esto es auxiliar, para poder usar km con las coordenadas\n",
    "\n",
    "min_points = 20  ### Elegimos que para que un punto sea considerado denso, debe haber al menos 20 puntos en su bola\n",
    "clu_highrad = DBSCAN(eps=epsilon, min_samples=min_points, metric='manhattan')  ## Usar dbscan, con metrica L1 o manhattan\n",
    "clu_highrad.fit(np.radians(datos_pob[['Lat','Lon']].values))\n",
    "\n",
    "etiqs_highrad = list(clu_highrad.labels_) ### Clusters encontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"600\"\n",
       "            src=\"pruebas/map_highrad.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1eedbcca860>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Plotear resultado clusters dbscan\n",
    "plotmap(etiqs_highrad, 'map_highrad')\n",
    "\n",
    "\n",
    "### Mostrar aqui el html\n",
    "from IPython.display import IFrame\n",
    "IFrame(src='pruebas/map_highrad.html', width=700, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este último caso, vemos que ocurre al poner un parámetro de radio de la bola muy alto (300m en vez de 180m). Lo que ocurre entonces es que al ser tan alto este valor, casi todas las bolas densas lograrán conectarse entre sí, generando entonces un supercluster muy grande como se muestra en la figura.\n",
    "\n",
    "Este valor no resulta tan indicado ya que se busca lograr una separación más adecuada entre las zonas de accidentalidad, aquí al usar ese valor tan alto el método no logra distinguir una zona de la otra correctamente. Sabemos que un valor de 300m resulta bastante alto ya que esto puede llegar a incluir varias calles, lo que conlleva a que todo se interconecte. En cambio, el valor original usado de 180m representaba un umbral mucho más justo, ya que con ese valor probablemente se agrupe máximo 1 o 2 intersecciones consecutivas una con la otra, lo que resulta mucho más adecuado y más razonable para poder armar los clusters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación del método y métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, se presentarán métricas para validar los resultados obtenidos por el mejor clustering de dbscan propuesto según el análisis de sensibilidad. Estos resultados serán comparados contra el método de clustering de K-means con el mismo número de clusters sobre el dataset. Se usarán distintos tipos de métricas para revaluar el rendimiento de cada tipo de clustering y se analizará cuál de los dos probablemente presente un mejor rendimiento según estas métricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Metodo de clustering: DBSCAN vs Kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestra como hubieran quedado los clusters al usar kmeans tradicional, para comparar su rendimiento con el cluster basado en densidad de dbscan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clustering con Kmeans\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_clusters=19 ## Este es el numero de clusters que hallo dbscan\n",
    "\n",
    "clu_k = KMeans(n_clusters=n_clusters, random_state=1)  ## Usar kmeans\n",
    "clu_k.fit(np.radians(datos_pob[['Lat','Lon']].values))\n",
    "\n",
    "etiqs_kmeans = list(clu_k.labels_) ### Clusters encontrados con kmeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"600\"\n",
       "            src=\"pruebas/map_kmeans.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1eedbcdc2b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Plot con Kmeans\n",
    "plotmap(etiqs_kmeans, 'map_kmeans')\n",
    "\n",
    "\n",
    "### Mostrar aqui el html\n",
    "from IPython.display import IFrame\n",
    "IFrame(src='pruebas/map_kmeans.html', width=700, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que kmeans utiliza una forma muy similar en todos sus clusters: un circulo con un centroide en alguna de las zonas. Esto no representa bien los datos ya que muchas de las zonas aqui analizadas tienen distintas formas y tamaños no es muy adecuado analizarlas con el kmeans. El ejemplo más claro de esto está en el Parque Lleras y la calle 10 (clusters que están debajo de la palabra \"Lalinde\"): toda esa región representa una zona muy frecuenta de la ciudad atravesad por la misma calle y toda esa calle tiene una dinámica muy similar (muchos accidentes por ser tan transitada), por esta razón es mucho más lógico agrupar todo el parque lleras y la calle 10 en un mismo cluster como lo hace dbscan que hacerlo como lo hace aquí kmeans. KMeans lo divide en dos clusters cuando no debería ser así, esto ocurre porque KMeans no es tan bueno para identificar clusters de distintas formas y tamaños, algo que sí hace mejor DBSCAN.\n",
    "\n",
    "Otro detalle importante son los outliers: hay accidentes que ocurrieron en regiones de muy baja accidentalidad que en realidad son más producto de la casualidad que de las condiciones de esa zona. DBSCAN hacía bien esta tarea al ser capaz de poner estos accidentes casuales como outliers que no representan en realidad clusters de accidentalida (no están en zonas densas). Por otro lado, KMeans siempre asignaba todos los puntos a todos los clusters, lo que no permite usar este método para detectar cuáles accidentes de verdad ocurren en los puntos de alta accidentalidad de la zona y cuales no, dándole entonces de nuevo la ventaja a DBSCAN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que ya se analizaron visualmente los resultados obtenidos por K-means, se puede pasar entonces a usar métricas para comparar ambos métodos de clustering.\n",
    "\n",
    "En este dataset, no se cuenta con una \"etiqueta real\" de a que cluster debería pertencer cada dato: simplemente le decimos a cada método que intente encontrar clusters de la mejor forma posible, pero no tenemos forma de saber si cada punto sí quedo en una cierta clase real ya que estas no existen (no conocemos con certezas la realidad de cómo se pueden agrupar las zonas de accidentalidad del Barrio El Poblado). Por este motivo, es necesario descartar el uso de cualquier tipo de métrica de validación que use criterios externos (es decir, las que usan las etiquetas reales son descartadas). Esto elimina la posibilidad de usar varias métricas que en otros tipos de problemas podrían ser de gran utilidad: son descartadas por ejemplo las métricas de entropía, pureza y F-measure, entre otras. \n",
    "\n",
    "No obstante, existen también métricas de validación internas (que no requieren las etiquetas reales de cada dato), y esas son las que se usan en este trabajo para validar los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, pasamos a evalaur algunas métricas para cada uno de los métodos. Las métricas se evaluarán para el clustering obtenido tanto por DBSCAN como por K-means. Adicionalmente, se evaluarán dos escenarios en DBSCAN: en el primero se considera que todo lo que marcó como outlier forma en sí un cluster, mientras que en el otro escenario se remueven todos los puntos clasificados como outliers y se conservan solo los demás puntos para evaluar la métrica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Coeficiente de silueta\n",
    "\n",
    "La primera métrica que usaremos para comparar los resultados es una de las métricas de valdiación interna más tradicionales para evaluar métodos de clustering: el coeficiente de silueta.\n",
    "\n",
    "Se debe tener en cuenta que esta métrica suele obtener valores mucho más altos cuando los clusters son convexos, como los de K-means, por encima de métodos que encuentran clusters no convexos, tal como lo hace DBSCAN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score Kmeans: 0.502132858149081\n",
      "Silhouette score DBSCAN (outliers como su propio cluster): 0.1718778655780877\n",
      "Silhouette score DBSCAN (quitando outliers): 0.2794134442429077\n"
     ]
    }
   ],
   "source": [
    "#### Coeficiente de silueta\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "### K means\n",
    "print('Silhouette score Kmeans: '+str(silhouette_score(np.radians(datos_pob[['Lat','Lon']].values), etiqs_kmeans, metric='cityblock')))\n",
    "\n",
    "### DBSCAN (outliers como su propio cluster)\n",
    "print('Silhouette score DBSCAN (outliers como su propio cluster): '+str(silhouette_score(np.radians(datos_pob[['Lat','Lon']].values), etiqs, metric='cityblock')))\n",
    "\n",
    "\n",
    "### DBSCAN (quitando outliers)\n",
    "print('Silhouette score DBSCAN (quitando outliers): '+str(silhouette_score(np.radians(datos_pob[['Lat','Lon']].values)[np.where(np.array(etiqs)>=0)[0]], np.array(etiqs)[np.where(np.array(etiqs)>=0)[0]], metric='cityblock')\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###### Calinski Harabasz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calinski Harabasz score Kmeans: 5388.651056846635\n",
      "Calinski Harabasz score DBSCAN (outliers como su propio cluster): 687.3284187521431\n",
      "Calinski Harabasz score DBSCAN (quitando outliers): 1725.099541697324\n"
     ]
    }
   ],
   "source": [
    "#### Coeficiente de silueta\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "\n",
    "### K means\n",
    "print('Calinski Harabasz score Kmeans: '+str(calinski_harabasz_score(np.radians(datos_pob[['Lat','Lon']].values), etiqs_kmeans)))\n",
    "\n",
    "### DBSCAN (outliers como su propio cluster)\n",
    "print('Calinski Harabasz score DBSCAN (outliers como su propio cluster): '+str(calinski_harabasz_score(np.radians(datos_pob[['Lat','Lon']].values), etiqs)))\n",
    "\n",
    "\n",
    "### DBSCAN (quitando outliers)\n",
    "print('Calinski Harabasz score DBSCAN (quitando outliers): '+str(calinski_harabasz_score(np.radians(datos_pob[['Lat','Lon']].values)[np.where(np.array(etiqs)>=0)[0]], np.array(etiqs)[np.where(np.array(etiqs)>=0)[0]])\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Davies Bouldin Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies Bouldin index Kmeans: 0.7034066694614008\n",
      "Davies Bouldin index DBSCAN (outliers como su propio cluster): 3.414140580500939\n",
      "Davies Bouldin index DBSCAN (quitando outliers): 0.637231429871977\n"
     ]
    }
   ],
   "source": [
    "#### Davies Bouldin Index\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "### K means\n",
    "print('Davies Bouldin index Kmeans: '+str(davies_bouldin_score(np.radians(datos_pob[['Lat','Lon']].values), etiqs_kmeans)))\n",
    "\n",
    "### DBSCAN (outliers como su propio cluster)\n",
    "print('Davies Bouldin index DBSCAN (outliers como su propio cluster): '+str(davies_bouldin_score(np.radians(datos_pob[['Lat','Lon']].values), etiqs)))\n",
    "\n",
    "\n",
    "### DBSCAN (quitando outliers)\n",
    "print('Davies Bouldin index DBSCAN (quitando outliers): '+str(davies_bouldin_score(np.radians(datos_pob[['Lat','Lon']].values)[np.where(np.array(etiqs)>=0)[0]], np.array(etiqs)[np.where(np.array(etiqs)>=0)[0]])\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DBCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reachability distances calculated for 0 points\n",
      "Reachability distances calculated for 100 points\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-9dde232799da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcityblock\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdbcv_kmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDBCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mradians\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatos_pob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Lat'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Lon'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metiqs_kmeans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcityblock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdbcv_outl_prop_clus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDBCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mradians\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatos_pob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Lat'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Lon'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metiqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcityblock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdbcv_quita_outl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDBCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mradians\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatos_pob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Lat'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Lon'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metiqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metiqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metiqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcityblock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Mis_documentos\\MaestriaCienciaDatos\\Semestre2\\AprendizajeMaq\\Github\\Apr\\tarea_4\\Archivos_auxiliares\\DBCV.py\u001b[0m in \u001b[0;36mDBCV\u001b[1;34m(X, labels, dist_function)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[0mindicating\u001b[0m \u001b[0mvalidity\u001b[0m \u001b[0mof\u001b[0m \u001b[0mclustering\u001b[0m \u001b[0massignments\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \"\"\"\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_mutual_reach_dist_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mmst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_mutual_reach_dist_MST\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mcluster_validity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_clustering_validity_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Mis_documentos\\MaestriaCienciaDatos\\Semestre2\\AprendizajeMaq\\Github\\Apr\\tarea_4\\Archivos_auxiliares\\DBCV.py\u001b[0m in \u001b[0;36m_mutual_reach_dist_graph\u001b[1;34m(X, labels, dist_function)\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[0mclass_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[0mclass_j\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mmembers_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_label_members\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m             \u001b[0mmembers_j\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_label_members\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_j\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             dist = _mutual_reachability_dist(point_i, point_j,\n",
      "\u001b[1;32m~\\Documents\\Mis_documentos\\MaestriaCienciaDatos\\Semestre2\\AprendizajeMaq\\Github\\Apr\\tarea_4\\Archivos_auxiliares\\DBCV.py\u001b[0m in \u001b[0;36m_get_label_members\u001b[1;34m(X, labels, cluster)\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[0mspecified\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \"\"\"\n\u001b[1;32m--> 261\u001b[1;33m     \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m     \u001b[0mmembers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmembers\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mwhere\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Calcular DBCV scores (el tiempo de computo es alto para estos, a veces varias horas)\n",
    "from Archivos_auxiliares.DBCV import DBCV\n",
    "from scipy.spatial.distance import cityblock\n",
    "\n",
    "dbcv_kmeans = DBCV(np.radians(datos_pob[['Lat','Lon']].values), np.array(etiqs_kmeans), dist_function=cityblock)\n",
    "dbcv_outl_prop_clus = DBCV(np.radians(datos_pob[['Lat','Lon']].values), np.array(etiqs), dist_function=cityblock)\n",
    "dbcv_quita_outl = DBCV(np.radians(datos_pob[['Lat','Lon']].values)[np.where(np.array(etiqs)>=0)[0]], np.array(etiqs)[np.where(np.array(etiqs)>=0)[0]], dist_function=cityblock)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Luego de calculados los DBCV scores, imprimir los resultados\n",
    "print('DBCV score Kmeans: ' + str(dbcv_kmeans))\n",
    "print('DBCV score DBSCAN (outliers como su propio cluster): ' + str(dbcv_outl_prop_clus))\n",
    "print('DBCV score DBSCAN (quitando outliers): ' + str(dbcv_quita_outl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Matriz de similitud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para validar los resultados de la clusterización final (la presentada al inicio) obtenida por DBSCAN, ordenamos los datos con respecto al cluster en que estos quedan y luego calculamos una matriz de similitud, la cual graficamos usando un mapa de calor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Ordenar datos segun clusters asignados\n",
    "lats_t = np.array([])\n",
    "long_t = np.array([])\n",
    "for i in range(max(etiqs)+1):\n",
    "    latitude_list = np.array(lat)[np.where(np.array(etiqs)==i)]\n",
    "    longitude_list = np.array(lon)[np.where(np.array(etiqs)==i)]    \n",
    "    lats_t = np.concatenate((lats_t, latitude_list), axis=0)\n",
    "    long_t = np.concatenate((long_t, longitude_list), axis=0)    \n",
    "\n",
    "### Juntar latitud y longitud en un dataframe\n",
    "fulldat = pd.DataFrame()\n",
    "fulldat['lat'] = lats_t\n",
    "fulldat['lon'] = long_t\n",
    "\n",
    "## Obtener matriz de distancias\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "distm = pd.DataFrame(squareform(pdist(fulldat),'cityblock'))\n",
    "\n",
    "### Cambiarla por matriz de similitudes\n",
    "simil_m = 1 - distm.values \n",
    "\n",
    "### Pintar mapa de calor\n",
    "import matplotlib.pyplot as plt\n",
    "def heatmap2d(arr: np.ndarray):\n",
    "    plt.figure()\n",
    "    plt.imshow(arr, cmap='seismic')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "heatmap2d(simil_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos en el mapa de calor de la matriz de similitud, los cuadros de color más rojo oscuro que se forman quedan en la diagonal de esta matriz. Esto indica entonces que los datos que quedaban en un mismo cluster sí eran muy similares entre sí (los cuadros rojos oscuros de la diagonal representan los clusters). Por ende, validamos entonces que los clusters obtenidos por DBSCAN sí están siendo buenas agrupaciones para los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otro lado, la matriz de similitud para los datos ordenados con K-means es:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ordenar datos segun clusters asignados\n",
    "lats_t = np.array([])\n",
    "long_t = np.array([])\n",
    "for i in range(max(etiqs_kmeans)+1):\n",
    "    latitude_list = np.array(lat)[np.where(np.array(etiqs_kmeans)==i)]\n",
    "    longitude_list = np.array(lon)[np.where(np.array(etiqs_kmeans)==i)]    \n",
    "    lats_t = np.concatenate((lats_t, latitude_list), axis=0)\n",
    "    long_t = np.concatenate((long_t, longitude_list), axis=0)    \n",
    "\n",
    "### Juntar latitud y longitud en un dataframe\n",
    "fulldat = pd.DataFrame()\n",
    "fulldat['lat'] = lats_t\n",
    "fulldat['lon'] = long_t\n",
    "\n",
    "## Obtener matriz de distancias\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "distm = pd.DataFrame(squareform(pdist(fulldat),'cityblock'))\n",
    "\n",
    "### Cambiarla por matriz de similitudes\n",
    "simil_m = 1 - distm.values \n",
    "\n",
    "### Pintar mapa de calor\n",
    "import matplotlib.pyplot as plt\n",
    "def heatmap2d(arr: np.ndarray):\n",
    "    plt.figure()\n",
    "    plt.imshow(arr, cmap='seismic')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "heatmap2d(simil_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los clusters de K-means también muestran que los datos agrupados en cada clusters son bastante similares. Sin embargo, se nota claramente que en este caso los clusters tienen tamaños mucho más similares entre sí. DBSCAN fue capaz de hallar clusters densos de tamaños mucho más variados, al mismo tiempo que presentaba elementos muy similares entre sí en cada uno de los clusters. Esto representaría una posible ventaja para DBSCAN: es capaz de encontrar clusters de tamaños y formas muy variadas, sin que eso disminuya lo similares que son los elementos de cada uno de sus clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se concluye entonces que es muy importante escoger bien los valores de los parámetros de radio de la bola y mínimo número de puntos para ser considerada densa para obtener buenos resultados, además de elegir bien la métrica de distancia. Además, se mostró que DBSCAN puede tener un desempeño mucho mejor que KMeans cuando los posibles clusters tienen formas y tamaños distintos y dependen de que tan pegados están los datos de cada grupo. Por último, se validaron los resultados de los clusters obtenidos por DBSCAN usando la matriz de similitud y se obtuvieron resultados satisfactorios."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
