{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solucion tarea 3 - Aprendizaje Supervisado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import recall_score \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "\n",
    "file_name = 'proc_models'\n",
    "logger = logging.getLogger()\n",
    "dir_log = f'data/logs/{file_name}.log'\n",
    "\n",
    "handler = RotatingFileHandler(dir_log, maxBytes=2000000, backupCount=10)\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format=\"%(asctime)s - %(process)d - %(name)s - %(levelname)s - %(message)s\",\n",
    "                    handlers = [handler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación y preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('data/data_accidentes.sqlite3')\n",
    "\n",
    "d_ini = dt.datetime(2017,6,1)\n",
    "d_fin = dt.datetime(2018,1,1)\n",
    "\n",
    "query = f\"\"\" SELECT * FROM\n",
    "            info\n",
    "            WHERE\n",
    "            TW >= '{d_ini}' AND\n",
    "            TW < '{d_fin}' AND\n",
    "            BARRIO = 'AguasFrias'\n",
    "            \"\"\"\n",
    "            \n",
    "data = pd.read_sql_query(query, conn)\n",
    "data['TW'] = pd.to_datetime(data['TW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Accidente'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Agregar otras features\n",
    "data['hora'] = data['TW'].dt.hour\n",
    "data['dia_sem'] = data['TW'].dt.dayofweek\n",
    "\n",
    "data= pd.get_dummies(data, columns=['hora'])\n",
    "data= pd.get_dummies(data, columns=['icon'])\n",
    "data= pd.get_dummies(data, columns=['dia_sem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature augmentation\n",
    "freq = '5H'\n",
    "variables = ['temperature','precipIntensity','apparentTemperature','dewPoint',\n",
    "             'humidity','windSpeed','cloudCover','visibility']\n",
    "\n",
    "data_aux = data.copy()\n",
    "data_aux.index = data_aux.TW\n",
    "data_aux = data_aux.sort_index()\n",
    "data_aux = data_aux.drop(columns = 'TW')\n",
    "resample_data = data_aux[variables].rolling(freq, closed = 'left').mean()\n",
    "\n",
    "data_pivot = data_aux.pivot_table(values=variables, index='TW',columns='BARRIO', aggfunc=sum)\n",
    "data_mean = data_pivot.rolling(freq, closed = 'left').mean().stack().reset_index(drop = False)\n",
    "\n",
    "col_means = [*data_mean.columns[:2]]\n",
    "for col in data_mean.columns[2:]:\n",
    "    col_means.append(col + '_mean')\n",
    "    \n",
    "data_mean.columns = col_means\n",
    "\n",
    "data = data.merge(data_mean, how = 'left', on = ['TW','BARRIO'])\n",
    "data = data.dropna().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[data['TW']<dt.datetime(2017,11,1)].reset_index(drop = True)\n",
    "data_test = data[data['TW']>=dt.datetime(2017,11,1)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_train.drop(\"Accidente\", 1).reset_index(drop=True)       # feature matrix \n",
    "y = data_train['Accidente'].reset_index(drop=True)               # target feature\n",
    "X = X[X.columns[2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_test.drop(\"Accidente\", 1).reset_index(drop=True)       # feature matrix \n",
    "y_test = data_test['Accidente'].reset_index(drop=True)               # target feature\n",
    "X_test = X_test[X_test.columns[2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_0 = int(len(y_train) - y_train.sum())\n",
    "tra_1 = int(y_train.sum())\n",
    "\n",
    "prop_deseada_under = 0.5\n",
    "mul_updown = (tra_0 * prop_deseada_under - tra_1 * (1 - prop_deseada_under)) / (tra_0 * prop_deseada_under)   \n",
    "fac_1 = int(tra_0 * (1 - mul_updown))\n",
    "\n",
    "ratio_u = {0 : fac_1, 1 : tra_1}\n",
    "rus = RandomUnderSampler(sampling_strategy = ratio_u, random_state=42)\n",
    "X_train_under, y_train_under = rus.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 56)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_under.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento y selección de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(108, 57, 98, 20), (112, 77, 66, 26, 108, 127), (88, 92, 80, 80), (93, 122, 105, 109, 29, 8), (27, 58, 7, 93), (113, 35, 43, 7, 69, 65), (26, 38, 81, 63), (27, 113, 94, 54, 96, 64), (47, 97, 65, 85), (20, 67, 67, 52, 67, 56)]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "layers_nn = []\n",
    "\n",
    "layer_lim_max = 7\n",
    "layer_lim_min = 4\n",
    "\n",
    "nodes_lim_max = 128\n",
    "nodes_lim_min = 6\n",
    "\n",
    "iter_max = 5\n",
    "\n",
    "for _ in range(iter_max):\n",
    "    for size in range(layer_lim_min, layer_lim_max + 1, 2):\n",
    "        vec = tuple(np.random.randint(nodes_lim_min, nodes_lim_max, size))\n",
    "        layers_nn.append(vec)\n",
    "\n",
    "print(layers_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "             'logistic':{\n",
    "                         'mod':LogisticRegression(random_state = 42),\n",
    "                         'par':{\n",
    "                             'penalty': ('l1','l2'),\n",
    "                             'solver': ('saga','lbfgs')\n",
    "                             \n",
    "                         }\n",
    "             },\n",
    "             'ridge_log':{\n",
    "                         'mod':RidgeClassifier(random_state = 42),\n",
    "                         'par':{\n",
    "                              'alpha':[0.2, 0.4, 0.6, 0.8, 1],\n",
    "                              'solver': ('auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga')\n",
    "                         }\n",
    "                     \n",
    "             },\n",
    "             'naiveBayes':{\n",
    "                         'mod':GaussianNB(),\n",
    "                         'par':{}\n",
    "                     \n",
    "             },\n",
    "             'bernoulli':{\n",
    "                         'mod':BernoulliNB(),\n",
    "                         'par':{\n",
    "                             'fit_prior':[True, False],\n",
    "                             'alpha': [0,0.2,0.4,0.6,0.8,1]\n",
    "                         }\n",
    "                     \n",
    "             },\n",
    "             'qda':{\n",
    "                         'mod':QuadraticDiscriminantAnalysis(),\n",
    "                         'par':{\n",
    "                             'reg_param':[0,0.3,0.5,0.7,0.9]\n",
    "                         }\n",
    "                     \n",
    "             },\n",
    "             'nn':{\n",
    "                         'mod' : MLPClassifier( solver = 'adam',shuffle = True, random_state= 42),\n",
    "                         'par':{\n",
    "                             'hidden_layer_sizes' : layers_nn,\n",
    "                             'activation' : ('logistic', 'relu','tanh','identity'),\n",
    "                             'learning_rate_init': [0.001,0.01,0.1,0.3,0.5,0.9],\n",
    "                             'alpha':[0.05, 0.1, 0.5 , 3, 5, 10, 20]\n",
    "                             }\n",
    "                     \n",
    "             },\n",
    "             'rforest':{\n",
    "                        'mod': RandomForestClassifier(random_state= 42),\n",
    "                        'par': {'n_estimators':[10,20,30,40,50,60,70,80,90,100,200,300,400,500],\n",
    "                                'max_depth': [None, 2, 4, 6, 8, 10, 20, 30],\n",
    "                                'criterion':('gini','entropy'),\n",
    "                                'bootstrap': [True,False]\n",
    "                               }\n",
    "             },\n",
    "             'xtree':{\n",
    "                        'mod': ExtraTreesClassifier(random_state = 42),\n",
    "                        'par': {'n_estimators':[10,20,30,40,50,60,70,80,90,100,200,300,400,500],\n",
    "                                'max_depth':[None, 2, 4, 6, 8, 10, 20, 30],\n",
    "                                'criterion':('gini','entropy'),\n",
    "                                'bootstrap': [True,False]}                     \n",
    "             },\n",
    "             'gradient':{\n",
    "                         'mod' : GradientBoostingClassifier(random_state = 42),\n",
    "                         'par' : {'loss' : ('deviance', 'exponential'),\n",
    "                                 'n_estimators': [10,20,30,40,50,60,70,80,90,100,200,300,400,500],\n",
    "                                 'max_depth' : [3, 4, 5, 6, 7, 8, 9],\n",
    "                                 'learning_rate':[0.1,0.3,0.5,0.7,0.9]\n",
    "                                 }\n",
    "             },\n",
    "             'xgboost':{\n",
    "                      'mod':XGBClassifier(random_state = 42),\n",
    "                      'par':{\n",
    "                           'n_estimators':[10,20,30,40,50,60,70,80,90,100,200,300,400,500],\n",
    "                           'max_depth': [ 2, 4, 6, 8, 10, 20, 30]\n",
    "                          }\n",
    "                      }\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "              'knn':{\n",
    "                        'mod': KNeighborsClassifier(),\n",
    "                        'par': {'n_neighbors':[1,3,5,7,10,20,30,50,100,200,300],\n",
    "                                'weights':('uniform','distance')\n",
    "                               }\n",
    "                        },\n",
    "                'SVM':\n",
    "                    {'mod':SVC(tol=0.0001),\n",
    "                         'par':{\n",
    "                            'kernel' : ('linear','poly','rbf','sigmoid')\n",
    "                              }\n",
    "                     }\n",
    "             \n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid(base_path, now_date, path_file, X, Y, models, score = 'roc_auc', cv = 2, n_proc = 2, random = False, n_iter = 10):    \n",
    "    \n",
    "    for name in models:\n",
    "\n",
    "        t_ini = time.time()\n",
    "\n",
    "        pipeline = Pipeline([('scaler', StandardScaler()), (name,  models[name]['mod'])])\n",
    "        parameters = {}          \n",
    "        for par in models[name]['par']:\n",
    "            aux = name + '__' +  par\n",
    "            parameters[aux] = models[name]['par'][par]\n",
    "        \n",
    "        if random:\n",
    "            mod_aux = RandomizedSearchCV(pipeline, parameters, n_jobs = n_proc,\\\n",
    "                              scoring = score, verbose=1, cv = cv, n_iter = n_iter)\n",
    "        else:\n",
    "            mod_aux = GridSearchCV(pipeline, parameters, n_jobs = n_proc,\\\n",
    "                              scoring = score, verbose=1, cv = cv)\n",
    "                \n",
    "        mod_aux.fit(X, Y)\n",
    "        models[name]['bestModel'] = mod_aux.best_estimator_\n",
    "        models[name]['roc'] = mod_aux.best_score_\n",
    "\n",
    "        selection_time = time.time() - t_ini\n",
    "\n",
    "        models[name]['selection_time'] = selection_time\n",
    "\n",
    "        sample_f_path = os.path.join(base_path, path_file, f'{name}_{now_date.strftime(\"%Y%m%d_%H%M\")}.sav')\n",
    "\n",
    "        joblib.dump(models[name]['bestModel'], sample_f_path)\n",
    "\n",
    "        print(f\"El tiempo de seleccion fue: {selection_time:0.3f} s\")\n",
    "        print(f\"El ROC de la familia {name} es: {models[name]['roc']:0.3f}\")\n",
    "        print('*'*80)\n",
    "        \n",
    "        logger.info(f\"El tiempo de seleccion fue: {selection_time:0.3f} s\")\n",
    "        logger.info(f\"El ROC de la familia {name} es: {models[name]['roc']:0.3f}\")\n",
    "        logger.info('*'*80)        \n",
    "       \n",
    "    mod_name = None\n",
    "    best_roc = 0\n",
    "    for name in models:\n",
    "        if models[name]['roc'] > best_roc:\n",
    "            mod_name = name\n",
    "            best_roc = models[name]['roc']\n",
    "\n",
    "    print(f\"El mejor modelo fue: {mod_name} con un ROC de: {best_roc}\")\n",
    "    \n",
    "    logger.info(f\"El mejor modelo fue: {mod_name} con un ROC de: {best_roc}\")\n",
    "    \n",
    "    return models, mod_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "base_path = os.getcwd()\n",
    "now_date = dt.datetime.now()\n",
    "path_file = 'data/models'\n",
    "models, mod_name = grid(base_path, \n",
    "                        now_date, \n",
    "                        path_file,  \n",
    "                        X_train_under, \n",
    "                        y_train_under, \n",
    "                        models, \n",
    "                        score = 'roc_auc', \n",
    "                        cv =3 , \n",
    "                        n_proc = 11,\n",
    "                        random = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tiempo de seleccion fue: 93.452 s \n",
    "\n",
    "El ROC de la familia logistic es: 0.712\n",
    "********************************************************************************\n",
    "\n",
    "El tiempo de seleccion fue: 263.394 s\n",
    "\n",
    "El ROC de la familia ridge_log es: 0.705\n",
    "********************************************************************************\n",
    "El tiempo de seleccion fue: 6.242 s\n",
    "\n",
    "El ROC de la familia naiveBayes es: 0.665\n",
    "********************************************************************************\n",
    "El tiempo de seleccion fue: 23.902 s\n",
    "\n",
    "El ROC de la familia bernoulli es: 0.655\n",
    "********************************************************************************\n",
    "El tiempo de seleccion fue: 40.451 s\n",
    "\n",
    "El ROC de la familia qda es: 0.686\n",
    "********************************************************************************\n",
    "El tiempo de seleccion fue: 1523.359 s\n",
    "\n",
    "El ROC de la familia nn es: 0.714\n",
    "********************************************************************************\n",
    "El tiempo de seleccion fue: 1263.119 s\n",
    "\n",
    "El ROC de la familia rforest es: 0.725\n",
    "********************************************************************************\n",
    "El tiempo de seleccion fue: 642.026 s\n",
    "\n",
    "El ROC de la familia xtree es: 0.707\n",
    "********************************************************************************\n",
    "El tiempo de seleccion fue: 6869.806 s\n",
    "\n",
    "El ROC de la familia gradient es: 0.731\n",
    "********************************************************************************\n",
    "El tiempo de seleccion fue: 6037.792 s\n",
    "\n",
    "El ROC de la familia xgboost es: 0.732\n",
    "********************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_final = {\n",
    "                     'rforest_final':{\n",
    "                                'mod': RandomForestClassifier(random_state= 42, bootstrap = True),\n",
    "                                'par': {'n_estimators':[10,20,30,40,50,60,70,80,90,100,300],\n",
    "                                        'max_depth': [None, 2, 4, 6, 8, 10, 20],\n",
    "                                        'criterion':('gini','entropy')\n",
    "                                       }\n",
    "                     }\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=11)]: Using backend LokyBackend with 11 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tiempo de seleccion fue: 1.823 s\n",
      "El ROC de la familia rforest_final es: 0.375\n",
      "********************************************************************************\n",
      "El mejor modelo fue: rforest_final con un ROC de: 0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=11)]: Done  10 out of  15 | elapsed:    1.7s remaining:    0.8s\n",
      "[Parallel(n_jobs=11)]: Done  15 out of  15 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "base_path = os.getcwd()\n",
    "now_date = dt.datetime.now()\n",
    "path_file = 'data/models'\n",
    "models, mod_name = grid(base_path, \n",
    "                        now_date, \n",
    "                        path_file,  \n",
    "                        X_train_under, \n",
    "                        y_train_under, \n",
    "                        modelo_final, \n",
    "                        score = 'roc_auc', \n",
    "                        cv =3 , \n",
    "                        n_proc = 11,\n",
    "                        random = True,\n",
    "                        n_iter = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tiempo de seleccion fue: 8220.335 s\n",
    "\n",
    "El ROC de la familia rforest_final es: 0.727"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desempeno del modelo en el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('data/models/rforest_final_20200225_2256.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = model.predict(X_test)\n",
    "probabilidades = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fscore = f1_score(y_test, predicciones)\n",
    "roc = roc_auc_score(y_test, probabilidades)\n",
    "sensibilidad = recall_score(y_test, predicciones)\n",
    "precision =precision_score(y_test, predicciones)\n",
    "b_accuracy = balanced_accuracy_score(y_test, predicciones)\n",
    "\n",
    "print(f'El roc es {roc}')\n",
    "print(f'La sensibilidad es {sensibilidad}')\n",
    "print(f'La precision es {precision}')\n",
    "print(f'El fscore es {fscore}')\n",
    "print(f'El balanced accuracy es {b_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x=y_test , y = probabilidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()  \n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, probabilidades, drop_intermediate=False)\n",
    "roc_auc = roc_auc_score(y_test, probabilidades)\n",
    "\n",
    "ax.plot(fpr, tpr, color='red', label=f'auc %0.5f' % roc_auc)    \n",
    "ax.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')    \n",
    "ax.set_title('Receiver operating characteristic (ROC)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis de Sensibilidad "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "rocs = []\n",
    "n_estimators = [10,20,30,40,50,60,70,80,90,100,200,300,]\n",
    "for n in n_estimators:\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators = n, random_state= 42, bootstrap = True)\n",
    "    \n",
    "    start = time.time()\n",
    "    clf.fit(X_train_under, y_train_under)\n",
    "    times.append(time.time() - start)\n",
    "    \n",
    "    preds = clf.predict_proba(X_val)[:,1]\n",
    "    \n",
    "    rocs.append(roc_auc_score(y_val, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure('roc vs Tiempo Computo - n_estimators')\n",
    "plt.plot(n_estimators,rocs)\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('ROC_AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure('n_estimators vs Tiempo Computo')\n",
    "plt.plot(n_estimators,times)\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Tiempo Computo (seg)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times2 = []\n",
    "rocs2 = []\n",
    "max_depth = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "for max_d in max_depth:\n",
    "    \n",
    "    clf = RandomForestClassifier(max_depth = max_d, random_state= 42, bootstrap = True)\n",
    "    \n",
    "    start = time.time()\n",
    "    clf.fit(X_train_under, y_train_under)\n",
    "    times2.append(time.time() - start)\n",
    "    \n",
    "    preds = clf.predict_proba(X_val)[:,1]\n",
    "    \n",
    "    rocs2.append(roc_auc_score(y_val, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure('roc vs Tiempo Computo - max_depth')\n",
    "plt.plot(max_depth,rocs2)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('ROC_AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure('max_depth vs Tiempo Computo')\n",
    "plt.plot(max_depth,times2)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Tiempo Computo (seg)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
